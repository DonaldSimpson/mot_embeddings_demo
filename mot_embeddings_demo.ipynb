{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0a5d42",
   "metadata": {},
   "source": [
    "\n",
    "# MOT Defect Embeddings Demo with MiniLM\n",
    "\n",
    "**Author:** Donald Simpson  \n",
    "**Data:** Contains public sector information licensed under the [Open Government Licence v3.0](https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/)\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "This notebook demonstrates how to use **embeddings** to analyse messy, unstructured text data - specifically MOT (Ministry of Transport) defect notes. You'll learn how to:\n",
    "\n",
    "- **Convert text to numbers**: Transform defect notes into numerical vectors that capture meaning\n",
    "- **Find hidden patterns**: Use clustering to group similar defects automatically  \n",
    "- **Search by meaning**: Find related defects using semantic search instead of keyword matching\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "MOT testers write defect notes in their own words: \"brake pipe corroded\", \"brake hose deteriorated\", \"brakes imbalanced\". Traditional keyword searches miss the connection between these different phrasings. Embeddings solve this by understanding that these all describe brake-related issues.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Just run each cell in order: the notebook will automatically install any missing dependencies.\n",
    "\n",
    "The first cell may take up to 30 seconds to install dependencies, the rest are all very quick.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DonaldSimpson/mot_embeddings_demo/blob/main/mot_embeddings_demo.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies automatically (only needed in Colab)\n",
    "try:\n",
    "    import sentence_transformers\n",
    "    import sklearn\n",
    "    import matplotlib\n",
    "    print(\"✅ All dependencies already installed!\")\n",
    "except ImportError:\n",
    "    print(\"📦 Installing required packages...\")\n",
    "    !pip install sentence-transformers scikit-learn matplotlib\n",
    "    print(\"✅ Installation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suppress Hugging Face authentication warnings (optional authentication)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf17e0",
   "metadata": {},
   "source": [
    "## Sample MOT Defect Notes\n",
    "\n",
    "Here's a small collection of real MOT defect notes for demonstration. Notice how different testers describe similar issues in various ways:\n",
    "\n",
    "- **Brake issues**: \"brake pipe corroded\" vs \"brake hose deteriorated\" vs \"brakes imbalanced\"\n",
    "- **Lighting problems**: \"headlamp aim too high\" \n",
    "- **Steering/suspension**: \"steering rack gaiter damaged\" vs \"excessive play in steering column\"\n",
    "\n",
    "This variety is exactly why traditional keyword searches struggle - but embeddings can see the underlying patterns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "notes = [\n",
    "    # Brake-related issues\n",
    "    \"Nearside rear brake pipe corroded\",\n",
    "    \"Brake hose deteriorated\", \n",
    "    \"Brakes imbalanced across an axle\",\n",
    "    \"Nearside rear brake hose perished\",\n",
    "    \"Brake disc worn and pitted\",\n",
    "    \"Brake pad material below minimum thickness\",\n",
    "    \"Brake fluid level low\",\n",
    "    \"Brake warning light illuminated\",\n",
    "    \n",
    "    # Lighting problems\n",
    "    \"Headlamp aim too high\",\n",
    "    \"Offside headlamp not working\",\n",
    "    \"Nearside rear light bulb failed\",\n",
    "    \"Fog light inoperative\",\n",
    "    \"Number plate light not functioning\",\n",
    "    \"Indicators not working properly\",\n",
    "    \n",
    "    # Steering and suspension\n",
    "    \"Steering rack gaiter damaged\",\n",
    "    \"Excessive play in steering column\",\n",
    "    \"Nearside rear suspension arm corroded\",\n",
    "    \"Shock absorber leaking\",\n",
    "    \"Steering wheel alignment incorrect\",\n",
    "    \"Suspension spring broken\",\n",
    "    \"Track rod end worn\",\n",
    "    \n",
    "    # Tyre and wheel issues\n",
    "    \"Offside front tyre worn close to legal limit\",\n",
    "    \"Nearside rear tyre sidewall damaged\",\n",
    "    \"Wheel bearing noisy\",\n",
    "    \"Tyre pressure monitoring system fault\",\n",
    "    \"Alloy wheel corroded\",\n",
    "    \n",
    "    # Engine and exhaust\n",
    "    \"Exhaust leaking gases\",\n",
    "    \"Engine oil leak\",\n",
    "    \"Catalytic converter inefficient\",\n",
    "    \"Air filter blocked\",\n",
    "    \"Engine management light on\",\n",
    "    \"Exhaust system corroded\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce62ca71",
   "metadata": {},
   "source": [
    "## Step 1: Generate Embeddings with MiniLM\n",
    "\n",
    "Now we'll convert our text notes into numerical vectors (embeddings) using the MiniLM model. Think of this as creating a unique \"fingerprint\" for each piece of text that captures its meaning.\n",
    "\n",
    "**What's happening here:**\n",
    "- Each defect note becomes a 384-dimensional vector\n",
    "- Notes with similar meanings will have similar vectors\n",
    "- The model was trained on millions of text examples to understand language patterns\n",
    "\n",
    "**MiniLM** is a lightweight but effective model - perfect for this demo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Loading MiniLM model (this may take a moment on first run)...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Converting text to embeddings...\")\n",
    "embeddings = model.encode(notes)\n",
    "print(f\"✅ Generated embeddings: {embeddings.shape}\")\n",
    "print(f\"📊 Processed {len(notes)} defect notes into {embeddings.shape[1]}-dimensional vectors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ad2f1",
   "metadata": {},
   "source": [
    "## Step 2: Clustering Defects with K-Means\n",
    "\n",
    "Now we'll group similar defects together automatically using K-means clustering. The algorithm will discover patterns in our embeddings and group related issues.\n",
    "\n",
    "**What's happening here:**\n",
    "- **K-means clustering** groups similar embeddings together\n",
    "- We're using 5 clusters to group our diverse defect types (you can experiment with different numbers)\n",
    "- **PCA (Principal Component Analysis)** reduces our 384-dimensional vectors to 2D for visualisation\n",
    "- The scatter plot shows how defects cluster together\n",
    "\n",
    "**Look for patterns:** You should see distinct clusters for brake issues, lighting problems, steering/suspension, tyres, and engine/exhaust defects. Each cluster represents a different type of vehicle problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Running K-means clustering...\")\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "print(\"Reducing dimensions for visualization...\")\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(embeddings)\n",
    "\n",
    "print(\"Creating visualization...\")\n",
    "plt.figure(figsize=(12,8))\n",
    "scatter = plt.scatter(reduced[:,0], reduced[:,1], c=labels, cmap=\"viridis\", s=100, alpha=0.7)\n",
    "\n",
    "# Add labels for each point\n",
    "for i, txt in enumerate(notes):\n",
    "    plt.annotate(txt, (reduced[i,0]+0.01, reduced[i,1]+0.01), fontsize=8, alpha=0.8)\n",
    "\n",
    "plt.title(\"Clustering MOT Defect Notes with MiniLM Embeddings\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"First Principal Component\", fontsize=12)\n",
    "plt.ylabel(\"Second Principal Component\", fontsize=12)\n",
    "plt.colorbar(scatter, label=\"Cluster\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Created {len(set(labels))} clusters from {len(notes)} defect notes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a779c",
   "metadata": {},
   "source": [
    "## Step 3: Semantic Search\n",
    "\n",
    "Finally, let's try semantic search - finding defects that are similar in meaning to a query, not just exact word matches.\n",
    "\n",
    "**What's happening here:**\n",
    "- We encode our search query \"brake failure\" into the same embedding space\n",
    "- **Cosine similarity** measures how similar our query is to each defect note\n",
    "- We rank results by similarity score (0.0 = no similarity, 1.0 = identical meaning)\n",
    "\n",
    "**Try different queries:** Change the query variable to \"tyre wear\", \"steering problem\", or \"engine issue\" to see how the model understands different concepts!\n",
    "\n",
    "**The magic:** Notice how \"brake failure\" finds brake-related defects even though none of them contain the word \"failure\" - that's semantic understanding in action!\n",
    "## Next Steps: Experiment and Explore\n",
    "\n",
    "Now that you understand the basics, here are some ways to experiment with this notebook:\n",
    "\n",
    "### Try These Modifications:\n",
    "\n",
    "1. **Add your own defect notes** - Replace the sample data with notes from your own vehicle's MOT history\n",
    "2. **Change the number of clusters** - Try `n_clusters=2`, `4`, or `5` to see how groupings change\n",
    "3. **Experiment with different queries** - Try \"safety concern\", \"performance issue\", or \"electrical fault\"\n",
    "4. **Try a different model** - Replace `\"all-MiniLM-L6-v2\"` with `\"multi-qa-mpnet-base-dot-v1\"` for potentially better results\n",
    "\n",
    "### Scale Up:\n",
    "\n",
    "- **Larger datasets**: Try with hundreds or thousands of MOT records\n",
    "- **Different domains**: Apply the same techniques to customer feedback, support tickets, or any unstructured text\n",
    "- **Production deployment**: Check out the [MLOps blog post](https://www.donaldsimpson.co.uk/2025/09/22/mlops-for-devops-engineers-minilm-mlflow-demo/) to see how to turn this into a production pipeline\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "This same approach powers [CarHunch](https://www.carhunch.com) - a platform that analyses millions of MOT records to provide vehicle insights. \n",
    "\n",
    "The techniques you've just learned can help people make informed decisions about their vehicles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334825d0",
   "metadata": {},
   "source": [
    "## Let's Try It: Semantic Search in Action\n",
    "\n",
    "Now let's run the semantic search to see how it works in practice. We'll search for \"brake failure\" and see which defect notes are most similar in meaning.\n",
    "\n",
    "**What this code does:**\n",
    "1. **Encode the query**: Convert \"brake failure\" into the same embedding space as our defect notes\n",
    "2. **Calculate similarities**: Use cosine similarity to find how similar our query is to each defect note\n",
    "3. **Rank results**: Sort by similarity score and show the top 5 matches\n",
    "4. **Display results**: Show each match with its similarity score (0.0 = no similarity, 1.0 = identical meaning)\n",
    "\n",
    "**The magic**: Notice how \"brake failure\" finds brake-related defects even though none of them contain the word \"failure\" - that's semantic understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7057fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the semantic search\n",
    "query = \"brake failure\"\n",
    "print(f\"🔍 Searching for: '{query}'\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "qvec = model.encode([query])\n",
    "sims = cosine_similarity(qvec, embeddings)[0]\n",
    "\n",
    "print(f\"Top 5 most similar defect notes:\\n\")\n",
    "top = np.argsort(-sims)[:5]\n",
    "for rank, i in enumerate(top, 1):\n",
    "    print(f\"{rank}. {notes[i]}\")\n",
    "    print(f\"   Similarity: {sims[i]:.3f} ({sims[i]*100:.1f}% match)\")\n",
    "    print()\n",
    "\n",
    "print(\"💡 Notice how 'brake failure' finds brake-related defects even though\")\n",
    "print(\"   none of them contain the word 'failure' - that's semantic understanding!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354695d",
   "metadata": {},
   "source": [
    "## What You've Just Learned\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "\n",
    "1. **Converted text to embeddings** - Transformed 32 MOT defect notes into 384-dimensional vectors\n",
    "2. **Discovered hidden patterns** - Used clustering to automatically group similar defects\n",
    "3. **Performed semantic search** - Found related defects by meaning, not just keywords\n",
    "\n",
    "**Key Insight**: Embeddings understand that \"brake failure\" is related to \"brake pipe corroded\" and \"brake hose deteriorated\" even though they use completely different words. This is the power of semantic understanding!\n",
    "\n",
    "**Real-World Impact**: These same techniques power [CarHunch](https://www.carhunch.com), helping people make informed decisions about their vehicles by analysing millions of MOT records.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
